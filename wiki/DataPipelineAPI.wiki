#labels Featured
==DataPipeline for programmers==

DataPipeline is written in the python language and can be extended by writing a custom Importer class or adding filters/functions. Users who know [http://www.python.org/ Python] and are interested in adding their own importers may find the information here useful. The code is compatible with Python versions>=2.5.

==Classes==

The (somewhat non-standard) diagram below shows how the core classes relate to the main components. We currently import several plotting and fitting methods from PEATDB, so this package is a dependency when installing the source package. Note that PEATDB has itself other dependencies such as ZODB, but these are not required for DataPipeline to work.

<img src=http://peat.googlecode.com/svn/wiki/images/datapipeline_classes.png width=800>

The core class is `Base.Pipeline` which handles all file reading/writing, queuing, fitting and joining of data, managing configuration files. 

The `BaseImporter` class does the actual import from the file, given a configuration. It has basic methods for getting rows, headers etc. This is always subclassed and the doImport method overridden to achieve the desired functionality. There are currently 8 Importer classes built in to DataPipeline that handle the most common text formats.
These are:

 * `DatabyColImporter`
 * `DatabyRowImporter`
 * `PairedDatabyColImporter`
 * `PairedDatabyRowImporter`
 * `GroupedDatabyColImporter`
 * `GroupedDatabyRowImporter`

See DataPipelineFormats

==Adding a custom importer==

To add your own custom importers, simple subclass the `BaseImporter` class and put the code in Custom.py so that the importer will be loaded automatically when required. 

 * Set the 'name' property of the importer, this label will be used in the _format_ keyword in the configuration file to identify your importer.
 * Override the doImport method at minimum.
 * Look at the other basic importers in Importer.py to see how the various methods are used such as getRowHeader() and so on. You can override these other methods if required, but generally they should be left alone.

A template for a new importer would look like this:

{{{
class MyCustomImporter(BaseImporter):
    """This importer handles data formatted in this format.. """

    name = 'mycustomimporter'

    def __init__(self, cp):
        BaseImporter.__init__(self, cp)
        return

    def doImport(self, lines):
        #your code here
}}}

==Adding filters/functions==

Pre-defined filters are implemented by the `Processor` class. The `doProcessingStep()` method of the Pipeline class (called when the `run()` method is executed) first checks that the names are found in the `predefined` attribute of the Processor class, if not the method returns.

{{{
X = Processor(self.functionsconf)
names = [i[1] for i in self.functions]
for n in names:
    if n not in X.predefined:
        print 'function %s not found' %n
        return data
data = X.doFunctions(names, data)
}}}

`Processor.doFunctions` then executes the filters simply by looping over the function names in the order they are defined in the configuration file.

For now, functions can simply be added by inserting new methods into the Processor class found in Processing.py. Also add the name of the function to the classes predefined attribute. New functions should be specified in the following form:

{{{
def somefunction(self, x, y):
    #process values here, if x or y is unchanged, just return it
    return newx,newy
}}}